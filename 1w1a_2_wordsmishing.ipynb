{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 금융문자 분석\n",
    "- 데이터 제공이 안된다.... \n",
    "- 베이스 라인 코드 따라쳐보고 의미 파악 하는 방향으로.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loveactualry/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm # 시간 측정\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # 벡터라이저 모델\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab 에서 사용 하는 경우 명령어.\n",
    "# colab을 써볼까??? \n",
    "# 환경 설정 걱정 안해도 될 것 같은데...\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수에 값들 세주기...\n",
    "Counter(train['smishing'])\n",
    "# 결과를 보면 스미싱과 아닌 것의 개수가 Counter({0: 277242, 1: 18703})\n",
    "# 비율 차이가 좀 있다.. \n",
    "# 산탄데르 문제와 비슷..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 램을 덜 차지하게 비율을 찾아보는 과정\n",
    "# under-sampling 방법\n",
    "19646/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2019) # 시드번호\n",
    "train_nsm_list=list(train[train['smishg']!=1].index\n",
    "# 0인 인덱스만 뽑아서 리스트를 만든다.\n",
    "train_nsmishing=random.sample(train_nsm_list, 11750)\n",
    "# 랜덤으로 11750개 샘플 뽑아서 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2019)\n",
    "train_sm_list=list(train[train['smishing']==1].index)\n",
    "train_smishing=random.sample(train_sm_list, 850 ) #0.066과 제일 비슷하게 나올 수 있도록  train data under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xx=train.iloc[train_smishing+train_nsmishing,:]\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "# reset index  보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xx=train.iloc[train_smishing+train_nsmishing,:].reset_index(drop=True) #under sampling으로 나온 index들로 train data 선별\n",
    "\n",
    "train_yy=DataFrame(train['smishing'],columns=['smishing']) \n",
    "train_yyy=train_yy.iloc[train_smishing+train_nsmishing,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임으로 데이터 넣어주기.test['smishing']=2 #train data와 동일한 형태 생성을 위해 임의의 숫자를 추가 #이후 스미싱 여부 확률 값으로 덮어 씌워짐\n",
    "test_xx=DataFrame(test['text'])\n",
    "test_yyy=DataFrame(test['smishing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mecab은 윈도우에서 작동하지 않는다.\n",
    "# tokenizer를 활용하는 다른 함수.\n",
    "# https://blog.pingpong.us/tokenizer/\n",
    "# 해당 사이트 참조 - Mecab이 성능이 더 좋다는 얘기가 있다.\n",
    "\n",
    "import konlpy\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "tokenizer = Mecab() # setting tokenizer using Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 토큰화 -> 토큰화를 하는 이유는 뭘까?\n",
    "tokenizer = Mecab() # setting tokenizer using Mecab()\n",
    "\n",
    "train_doc = [ ( tokenizer.pos(x), y ) for x, y in tqdm( zip( train_xx['text'], train_yyy['smishing'] ) )  ] # Mecab를 활용하여 text를 토큰화 시킴\n",
    "test_doc = [ ( tokenizer.pos(x), y ) for x, y in tqdm( zip( test_xx['text'], test_yyy['smishing'] ) )  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 필요없는 단어를 제거해봅시다.\n",
    "\n",
    "stopwords = ['XXX', '.', '을', '를', '이', '가', '-', '(', ')', ':', '!', '?', ')-', '.-', 'ㅡ', 'XXXXXX', '..', '.(', '은', '는'] #필요없는 단어 리스트\n",
    "\n",
    "def get_couple(_words): #필요없는 단어들 없애는 함수\n",
    "    global stopwords # global을 왜 쓰나..?\n",
    "    _words = [x for x in _words if x[0] not in stopwords]\n",
    "    l = len(_words)\n",
    "    for i in range(l-1):\n",
    "        yield _words[i][0], _words[i+1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = [], []\n",
    "for lwords in train_doc:\n",
    "    Y_train.append(lwords[1])\n",
    "    \n",
    "    temp = []\n",
    "    for x, y in get_couple(lwords[0]):\n",
    "        temp.append(\"{}.{}\".format(x, y))\n",
    "    \n",
    "    X_train.append(\" \".join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 벡터화...\n",
    "v=CountVectorizer()\n",
    "\n",
    "v.fit(X_train)\n",
    "\n",
    "vec_x_train= v.transform(X_train).toarray()\n",
    "vec_x_test= v.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이브 베이즈 multinomial nb\n",
    "# 코드는 간단하구만.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1= MultinomialNB()\n",
    "m1.fit(vec_x_train,Y_train)\n",
    "\n",
    "y_train_pred1=m1.predict_proba(vec_x_train)\n",
    "y_train_pred1_one= [ i[1]  for i in y_train_pred1]\n",
    "\n",
    "y_test_pred1=m1.predict_proba(vec_x_test)\n",
    "y_test_pred1_one= [ i[1]  for i in y_test_pred1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
